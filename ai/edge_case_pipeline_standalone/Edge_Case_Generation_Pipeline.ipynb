{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhvDj3L9_4Rn"
   },
   "source": [
    "# Pixelated Empathy: Edge Case Generation Pipeline\n",
    "\n",
    "This notebook generates challenging therapy scenarios for training difficult client simulation models.\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions:**\n",
    "1. Run each cell in order.\n",
    "2. Configure your API key and model.\n",
    "3. Generate prompts and conversations.\n",
    "4. Analyze and export results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEE3v5su_4Rq"
   },
   "outputs": [],
   "source": [
    "# Install requirements if needed (uncomment if running in Colab)\n",
    "!pip install openai anthropic pandas numpy tqdm matplotlib seaborn ipywidgets requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LUBI4eV_4Rr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Import the edge case generator\n",
    "from edge_case_generator import EdgeCaseGenerator\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HUE_abN_4Rs"
   },
   "source": [
    "## üîß Configuration\n",
    "\n",
    "Choose your API provider and configure settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsGTKVQa_4Rs"
   },
   "outputs": [],
   "source": [
    "api_provider_widget = widgets.Dropdown(\n",
    "    options=[\"openai\", \"anthropic\", \"ollama\"],\n",
    "    value=\"ollama\",\n",
    "    description=\"API Provider:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "api_key_widget = widgets.Password(\n",
    "    placeholder=\"Enter your API key (not needed for Ollama)\",\n",
    "    description=\"API Key:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "model_widget = widgets.Dropdown(\n",
    "    options={\n",
    "        \"GPT-3.5 Turbo\": \"gpt-3.5-turbo\",\n",
    "        \"GPT-4\": \"gpt-4\",\n",
    "        \"GPT-4 Turbo\": \"gpt-4-turbo-preview\",\n",
    "        \"Claude 3 Haiku\": \"claude-3-haiku-20240307\",\n",
    "        \"Claude 3 Sonnet\": \"claude-3-sonnet-20240229\",\n",
    "        \"Claude 3 Opus\": \"claude-3-opus-20240229\",\n",
    "        \"Custom Ollama Model\": \"artifish/llama3.2-uncensored\",\n",
    "    },\n",
    "    value=\"gpt-3.5-turbo\",\n",
    "    description=\"Model:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "custom_model_widget = widgets.Text(\n",
    "    placeholder=\"Enter custom model name (for Ollama)\",\n",
    "    description=\"Custom Model:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "scenarios_per_category_widget = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"Scenarios per category:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "max_conversations_widget = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=10,\n",
    "    max=500,\n",
    "    step=10,\n",
    "    description=\"Max conversations to generate:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=\"edge_case_output\",\n",
    "    description=\"Output directory:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    ")\n",
    "display(\n",
    "    widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(\"<h3>üîß Configuration</h3>\"),\n",
    "            api_provider_widget,\n",
    "            api_key_widget,\n",
    "            model_widget,\n",
    "            custom_model_widget,\n",
    "            scenarios_per_category_widget,\n",
    "            max_conversations_widget,\n",
    "            output_dir_widget,\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X98pj-Z_4Rt"
   },
   "source": [
    "## üìä Preview Edge Case Categories\n",
    "\n",
    "Let's see what categories we'll be generating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3_7-4fk_4Rt"
   },
   "outputs": [],
   "source": [
    "temp_generator = EdgeCaseGenerator()\n",
    "categories = temp_generator.edge_case_categories\n",
    "category_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Category\": cat,\n",
    "            \"Description\": details[\"description\"],\n",
    "            \"Difficulty\": details[\"difficulty\"],\n",
    "            \"Challenges\": (\n",
    "                \", \".join(details[\"challenges\"][:2]) + \"...\"\n",
    "                if len(details[\"challenges\"]) > 2\n",
    "                else \", \".join(details[\"challenges\"])\n",
    "            ),\n",
    "        }\n",
    "        for cat, details in categories.items()\n",
    "    ]\n",
    ")\n",
    "print(f\"üìã Total Categories: {len(category_df)}\")\n",
    "print(f\"üéØ Total Scenarios to Generate: {len(category_df) * scenarios_per_category_widget.value}\")\n",
    "display(HTML(category_df.to_html(index=False, escape=False)))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "difficulty_counts = category_df[\"Difficulty\"].value_counts()\n",
    "ax[0].pie(difficulty_counts.values, labels=difficulty_counts.index, autopct=\"%1.1f%%\")\n",
    "ax[0].set_title(\"Difficulty Level Distribution\")\n",
    "sns.countplot(data=category_df, x=\"Difficulty\", ax=ax[1])\n",
    "ax[1].set_title(\"Categories by Difficulty Level\")\n",
    "ax[1].set_xlabel(\"Difficulty Level\")\n",
    "ax[1].set_ylabel(\"Number of Categories\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR4V7AJe_4Rt"
   },
   "source": [
    "## üöÄ Initialize Generator\n",
    "\n",
    "Set up the generator with your chosen configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7q2xZfF_4Ru"
   },
   "outputs": [],
   "source": [
    "api_provider = api_provider_widget.value\n",
    "api_key = api_key_widget.value if api_key_widget.value else None\n",
    "model_name = custom_model_widget.value if model_widget.value == \"custom\" else model_widget.value\n",
    "scenarios_per_category = scenarios_per_category_widget.value\n",
    "max_conversations = max_conversations_widget.value\n",
    "output_dir = output_dir_widget.value\n",
    "print(f\"üîß Configuration:\")\n",
    "print(f\"   API Provider: {api_provider}\")\n",
    "print(f\"   Model: {model_name}\")\n",
    "print(f\"   Scenarios per category: {scenarios_per_category}\")\n",
    "print(f\"   Max conversations: {max_conversations}\")\n",
    "print(f\"   Output directory: {output_dir}\")\n",
    "try:\n",
    "    generator = EdgeCaseGenerator(\n",
    "        api_provider=api_provider,\n",
    "        api_key=api_key,\n",
    "        model_name=model_name,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "    print(\"‚úÖ Generator initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing generator: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhJgLphj_4Ru"
   },
   "source": [
    "## üìù Step 1: Generate Prompts\n",
    "\n",
    "First, we'll generate all the prompts for our edge cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhCx5b7S_4Ru"
   },
   "outputs": [],
   "source": [
    "print(\"üìù Generating prompts...\")\n",
    "prompts = generator.generate_prompts(scenarios_per_category=scenarios_per_category)\n",
    "print(f\"‚úÖ Generated {len(prompts)} prompts\")\n",
    "print(f\"üìÅ Saved to: {generator.output_dir}/edge_case_prompts.jsonl\")\n",
    "print(\"\n",
    "üìã Sample prompts:\")\n",
    "for i, prompt in enumerate(prompts[:3]):\n",
    "    print(f\"\n",
    "{i+1}. {prompt['scenario_id']} ({prompt['category']})\")\n",
    "    print(f\"   Difficulty: {prompt['difficulty_level']}\")\n",
    "    print(f\"   Instructions: {prompt['instructions'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-sJG4Nd_4Ru"
   },
   "source": [
    "## ü§ñ Step 2: Generate Conversations\n",
    "\n",
    "Now we'll use the API to generate realistic therapy conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMmQdJH9_4Ru"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm_nb\n",
    "progress_widget = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=min(len(prompts), max_conversations),\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    style={'bar_width': '50px'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "status_widget = widgets.HTML(value=\"Starting generation...\")\n",
    "display(widgets.VBox([progress_widget, status_widget]))\n",
    "print(f\"ü§ñ Generating conversations using {api_provider} ({model_name})...\")\n",
    "print(f\"üìä Target: {min(len(prompts), max_conversations)} conversations\")\n",
    "print(\"\n",
    "‚è≥ This may take a while depending on your API provider and limits...\")\n",
    "conversations = []\n",
    "try:\n",
    "    for i, prompt in enumerate(tqdm_nb(prompts[:max_conversations])):\n",
    "        conv = generator._generate_single_conversation(prompt)\n",
    "        if conv:\n",
    "            conversations.append(conv)\n",
    "        progress_widget.value = i + 1\n",
    "        status_widget.value = f'Generated {i+1}/{min(len(prompts), max_conversations)}'\n",
    "    print(f'\n",
    "‚úÖ Generation completed!')\n",
    "    print(f'üìà Success rate: {len(conversations)/min(len(prompts), max_conversations)*100:.1f}%')\n",
    "except Exception as e:\n",
    "    status_widget.value = f'‚ùå Error: {str(e)}'\n",
    "    print(f'\n",
    "‚ùå Error during generation: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWCK_cAp_4Rv"
   },
   "source": [
    "## üìä Step 3: Analyze Results\n",
    "\n",
    "Let's analyze what we generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iXHZmjh_4Rv"
   },
   "outputs": [],
   "source": [
    "if conversations:\n",
    "    analysis_data = []\n",
    "    total_qa_pairs = 0\n",
    "    for conv in conversations:\n",
    "        qa_count = len(conv.get('qa_pairs', []))\n",
    "        total_qa_pairs += qa_count\n",
    "        analysis_data.append({\n",
    "            'Scenario ID': conv['scenario_id'],\n",
    "            'Category': conv['category'],\n",
    "            'Difficulty': conv['difficulty_level'],\n",
    "            'QA Pairs': qa_count,\n",
    "            'Has Content': qa_count > 0\n",
    "        })\n",
    "    analysis_df = pd.DataFrame(analysis_data)\n",
    "    print(f'üìä Analysis Results:')\n",
    "    print(f'   Total Conversations: {len(conversations)}')\n",
    "    print(f'   Total Q&A Pairs: {total_qa_pairs}')\n",
    "    print(f'   Average Q&A per Conversation: {total_qa_pairs/len(conversations):.1f}')\n",
    "    print(f'   Success Rate: {analysis_df[\"Has Content\"].sum()/len(analysis_df)*100:.1f}%')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    category_counts = analysis_df['Category'].value_counts()\n",
    "    category_counts.plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "    axes[0,0].set_title('Conversations by Category')\n",
    "    axes[0,0].set_xlabel('Category')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    difficulty_counts = analysis_df['Difficulty'].value_counts()\n",
    "    axes[0,1].pie(difficulty_counts.values, labels=difficulty_counts.index, autopct='%1.1f%%')\n",
    "    axes[0,1].set_title('Distribution by Difficulty')\n",
    "    analysis_df['QA Pairs'].hist(bins=20, ax=axes[1,0], color='lightgreen', alpha=0.7)\n",
    "    axes[1,0].set_title('Q&A Pairs per Conversation')\n",
    "    axes[1,0].set_xlabel('Number of Q&A Pairs')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    success_by_category = analysis_df.groupby('Category')['Has Content'].mean().sort_values(ascending=False)\n",
    "    success_by_category.plot(kind='bar', ax=axes[1,1], color='coral')\n",
    "    axes[1,1].set_title('Success Rate by Category')\n",
    "    axes[1,1].set_xlabel('Category')\n",
    "    axes[1,1].set_ylabel('Success Rate')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if conversations and conversations[0].get('qa_pairs'):\n",
    "        print('\n",
    "üí¨ Sample Generated Conversation:')\n",
    "        sample_conv = conversations[0]\n",
    "        print(f'Scenario: {sample_conv['scenario_id']} ({sample_conv['category']})')\n",
    "        print(f'Difficulty: {sample_conv['difficulty_level']}')\n",
    "        print('Dialogue:')\n",
    "        for i, qa in enumerate(sample_conv['qa_pairs'][:2]):\n",
    "            print(f'\n",
    "Therapist: {qa['prompt']}')\n",
    "            print(f'Client: {qa['response']}')\n",
    "        if len(sample_conv['qa_pairs']) > 2:\n",
    "            print(f'\n",
    "... ({len(sample_conv['qa_pairs']) - 2} more exchanges)')\n",
    "else:\n",
    "    print('‚ùå No conversations generated. Please check your configuration and try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjP4hjyN_4Rv"
   },
   "source": [
    "## üîÑ Step 4: Create Training Format\n",
    "\n",
    "Convert to the format needed for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWX588NQ_4Rv"
   },
   "outputs": [],
   "source": [
    "if conversations:\n",
    "    print('üîÑ Converting to training format...')\n",
    "    training_data = generator.create_training_format(conversations)\n",
    "    print(f'\n",
    "‚úÖ Created {len(training_data)} training examples')\n",
    "    print(f'üìÅ Saved to: {generator.output_dir}/edge_cases_training_format.jsonl')\n",
    "    if training_data:\n",
    "        print('\n",
    "üìã Sample Training Data:')\n",
    "        sample = training_data[0]\n",
    "        print(f'Category: {sample['category']}')\n",
    "        print(f'Difficulty: {sample['difficulty_level']}')\n",
    "        print(f'Purpose: {sample['purpose']}')\n",
    "        print(f'Prompt: {sample['prompt'][:100]}...')\n",
    "        print(f'Response: {sample['response'][:100]}...')\n",
    "else:\n",
    "    print('‚ùå No conversations available for training format conversion.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCMHKA2x_4Rv"
   },
   "source": [
    "## üìÑ Step 5: Generate Summary Report\n",
    "\n",
    "Create a comprehensive report of the generation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xI83wpv1_4Rv"
   },
   "outputs": [],
   "source": [
    "if conversations:\n",
    "    print('üìÑ Generating summary report...')\n",
    "    report = generator.generate_summary_report(conversations)\n",
    "    print(f'\n",
    "‚úÖ Report generated and saved to: {generator.output_dir}/summary_report.md')\n",
    "    print('\n",
    "' + '='*60)\n",
    "    print(report)\n",
    "    print('='*60)\n",
    "else:\n",
    "    print('‚ùå No conversations available for report generation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bg5thlLf_4Rv"
   },
   "source": [
    "## üìÅ File Management\n",
    "\n",
    "View and manage your generated files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4WeZVBs_4Rv"
   },
   "outputs": [],
   "source": [
    "output_path = Path(output_dir)\n",
    "if output_path.exists():\n",
    "    files = list(output_path.glob('*'))\n",
    "    print(f'üìÅ Files in {output_path}:')\n",
    "    print('-' * 50)\n",
    "    total_size = 0\n",
    "    for file in sorted(files):\n",
    "        if file.is_file():\n",
    "            size = file.stat().st_size\n",
    "            total_size += size\n",
    "            print(f'üìÑ {file.name:<30} {size:>10,} bytes')\n",
    "    print('-' * 50)\n",
    "    print(f'üìä Total size: {total_size:,} bytes ({total_size/1024/1024:.1f} MB)')\n",
    "    import zipfile\n",
    "    zip_path = Path(f'{output_dir}_complete.zip')\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file in files:\n",
    "            if file.is_file():\n",
    "                zipf.write(file, file.name)\n",
    "    print(f'\n",
    "üì¶ Created zip file: {zip_path}')\n",
    "    print(f'üíæ Zip size: {zip_path.stat().st_size:,} bytes')\n",
    "else:\n",
    "    print(f'‚ùå Output directory {output_path} not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgSi5RU__4Rv"
   },
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "- Review sample conversations for realism and appropriateness\n",
    "- Integrate with your main training pipeline\n",
    "- Use in evaluation framework\n",
    "- Download results before your Colab session ends!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy generating! ü§ñ‚ú®**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}