{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cELkt30NaJk_",
   "metadata": {
    "id": "cELkt30NaJk_"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-training-course/colab/finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmtraining-colab} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7693a36b-5cdc-4582-844b-8dd52fa522c5",
   "metadata": {
    "id": "7693a36b-5cdc-4582-844b-8dd52fa522c5"
   },
   "source": [
    "# Training a 3B Llama on instruction dataset with Weights & Biases, HuggingFace, LoRA and Quantization\n",
    "\n",
    "Tested on Google Colab V100 GPU. Check out [W&B HuggingFace documentation](https://docs.wandb.ai/guides/integrations/huggingface) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ef319f-bf26-4192-8951-8d536181ab67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4134,
     "status": "ok",
     "timestamp": 1746977447270,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     },
     "user_tz": 240
    },
    "id": "03ef319f-bf26-4192-8951-8d536181ab67",
    "outputId": "c6c083b7-b170-4b10-e225-d68eebf846e0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (3.20.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U wandb transformers trl accelerate peft bitsandbytes datasets evaluate sentencepiece \"protobuf==3.20.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "D_x8mMbGKb67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1746977448073,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     },
     "user_tz": 240
    },
    "id": "D_x8mMbGKb67",
    "outputId": "00f52a9e-c4b6-4d60-b07c-e760f2583eb2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2025-05-11 15:30:48--  https://github.com/wandb/edu/raw/main/llm-training-course/colab/utils.py\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/wandb/edu/main/llm-training-course/colab/utils.py [following]\n",
      "--2025-05-11 15:30:49--  https://raw.githubusercontent.com/wandb/edu/main/llm-training-course/colab/utils.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8155 (8.0K) [text/plain]\n",
      "Saving to: ‘utils.py.2’\n",
      "\n",
      "utils.py.2          100%[===================>]   7.96K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-05-11 15:30:49 (102 MB/s) - ‘utils.py.2’ saved [8155/8155]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/wandb/edu/raw/main/llm-training-course/colab/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04c0a5-f481-4364-880d-10c254388987",
   "metadata": {
    "id": "da04c0a5-f481-4364-880d-10c254388987"
   },
   "source": [
    "Let's grab the Alpaca (GPT-4 curated instructions and outputs) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a154f968-da0f-4bdc-bf45-e499d95f0606",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "a154f968-da0f-4bdc-bf45-e499d95f0606",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977455320,
     "user_tz": 240,
     "elapsed": 7246,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    },
    "outputId": "d71ac4f9-e3d4-4395-e2da-8386795f4339"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvivirox\u001b[0m (\u001b[33mgem-city-xyz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250511_153052-antnqaww</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gem-city-xyz/alpaca_ft/runs/antnqaww' target=\"_blank\">winter-glade-11</a></strong> to <a href='https://wandb.ai/gem-city-xyz/alpaca_ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/gem-city-xyz/alpaca_ft' target=\"_blank\">https://wandb.ai/gem-city-xyz/alpaca_ft</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/gem-city-xyz/alpaca_ft/runs/antnqaww' target=\"_blank\">https://wandb.ai/gem-city-xyz/alpaca_ft/runs/antnqaww</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1 of 2 files downloaded...\r\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"alpaca_ft\",  # the project I am working on\n",
    "    job_type=\"train\",\n",
    "    tags=[\"hf_sft_lora\", \"3b\"],\n",
    ")  # the Hyperparameters I want to keep track of\n",
    "artifact = wandb.use_artifact(\"capecape/alpaca_ft/alpaca_gpt4_splitted:v4\", type=\"dataset\")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811291cc-b7ce-422a-8971-3cbf9fe10a7f",
   "metadata": {
    "id": "811291cc-b7ce-422a-8971-3cbf9fe10a7f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977456988,
     "user_tz": 240,
     "elapsed": 1660,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "alpaca_ds = load_dataset(\"json\", data_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Asdi_3G1EFsz",
   "metadata": {
    "id": "Asdi_3G1EFsz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977457019,
     "user_tz": 240,
     "elapsed": 29,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Let's subsample the training and test dataset - you may want to switch to full dataset in your experiments\n",
    "alpaca_ds[\"train\"] = alpaca_ds[\"train\"].select(range(512))\n",
    "alpaca_ds[\"test\"] = alpaca_ds[\"test\"].select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb96e0-b2f2-4a79-ba65-e1c8d6395d54",
   "metadata": {
    "id": "26cb96e0-b2f2-4a79-ba65-e1c8d6395d54"
   },
   "source": [
    "Let's log the dataset also as a table so we can inspect it on the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5caaf114-3350-4570-b4d4-fb090399cc73",
   "metadata": {
    "id": "5caaf114-3350-4570-b4d4-fb090399cc73",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977457027,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "def prompt_no_input(row):\n",
    "    return (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\\n{output}\"\n",
    "    ).format_map(row)\n",
    "\n",
    "\n",
    "def prompt_input(row):\n",
    "    return (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n{output}\"\n",
    "    ).format_map(row)\n",
    "\n",
    "\n",
    "def create_prompt(row):\n",
    "    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_input(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7dda87-d70a-470b-a0f9-040af434dc42",
   "metadata": {
    "id": "4c7dda87-d70a-470b-a0f9-040af434dc42",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977457057,
     "user_tz": 240,
     "elapsed": 24,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = alpaca_ds[\"train\"]\n",
    "eval_dataset = alpaca_ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
   "metadata": {
    "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977459786,
     "user_tz": 240,
     "elapsed": 2727,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
   "metadata": {
    "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977459791,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"openlm-research/open_llama_3b_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2duDODtwaWrA",
   "metadata": {
    "id": "2duDODtwaWrA"
   },
   "source": [
    "Let's define our configurations for LoRA, quantization and model training so that it fits on our GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e625f5-e901-41e6-8045-0da0ad455728",
   "metadata": {
    "id": "b8e625f5-e901-41e6-8045-0da0ad455728",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977464162,
     "user_tz": 240,
     "elapsed": 4370,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=64,  # the rank of the LoRA matrices\n",
    "    lora_alpha=16,  # the weight\n",
    "    lora_dropout=0.1,  # dropout to add to the LoRA layers\n",
    "    bias=\"none\",  # add bias to the nn.Linear layers?\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "    ],  # the name of the layers to add LoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "_9n8JJ1ZE7RI",
   "metadata": {
    "id": "_9n8JJ1ZE7RI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977464175,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c10f7f-2551-4aa4-aef2-29c888b57a12",
   "metadata": {
    "id": "51c10f7f-2551-4aa4-aef2-29c888b57a12",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977464181,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    device_map={\"\": 0},\n",
    "    trust_remote_code=True,\n",
    "    # low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    # use_flash_attention_2=True,\n",
    "    use_cache=False,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c78dee3-218a-4ee0-9883-f33209c4faaf",
   "metadata": {
    "id": "1c78dee3-218a-4ee0-9883-f33209c4faaf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977464185,
     "user_tz": 240,
     "elapsed": 2,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "gradient_accumulation_steps = 16\n",
    "num_train_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb03a22-b31b-4250-bb2c-e51d43111623",
   "metadata": {
    "id": "feb03a22-b31b-4250-bb2c-e51d43111623"
   },
   "source": [
    "We'll add a `report_to=\"wandb\"` flag here to get the benefits of [W&B HuggingFace integration](https://docs.wandb.ai/guides/integrations/huggingface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c86339ca-27e5-496b-9559-3a65bb3c26a1",
   "metadata": {
    "id": "c86339ca-27e5-496b-9559-3a65bb3c26a1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977464486,
     "user_tz": 240,
     "elapsed": 299,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer  # Ensure SFTTrainer is imported if you are using it\n",
    "\n",
    "# Explicitly set WANDB_LOG_MODEL to \"end\" to log the model at the end of training.\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"false\"\n",
    "\n",
    "output_dir = \"./output/\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=\"alpaca-3b-finetune-run\",  # Fixes the run_name warning\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    fp16=True,\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs=dict(\n",
    "        use_reentrant=False\n",
    "    ),  # Make sure this is compatible with your library versions\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e35a9b70-f36b-4bfd-857f-c80d3450e111",
   "metadata": {
    "id": "e35a9b70-f36b-4bfd-857f-c80d3450e111",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977480531,
     "user_tz": 240,
     "elapsed": 16041,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    },
    "outputId": "09f3dc57-5c47-4333-f9c6-3e570c5ff7bd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from utils import LLMSampleCB\n",
    "\n",
    "# Remove model_init_kwargs and pass the model configuration directly to the model argument\n",
    "trainer = SFTTrainer(\n",
    "    model=AutoModelForCausalLM.from_pretrained(model_id, **model_kwargs),  # Pass model_kwargs here\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    # 'packing_strategy' is replaced with 'packing'\n",
    "    # packing=\"padding\",  # Changed 'packing_strategy' to 'packing' #This is incorrect and needs to be removed.\n",
    "    # max_seq_length=1024, # Remove this line, the parameter is no longer supported\n",
    "    args=training_args,\n",
    "    formatting_func=create_prompt,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "# Now you can access trainer's attributes\n",
    "trainer.processing_class.model_max_length = (\n",
    "    1024  # This is where the max_seq_length should be set instead\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0dbcb42-1e94-4f68-9edf-102f337ebf14",
   "metadata": {
    "id": "c0dbcb42-1e94-4f68-9edf-102f337ebf14",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977480547,
     "user_tz": 240,
     "elapsed": 14,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "# remove answers\n",
    "def create_prompt_no_anwer(row):\n",
    "    row[\"output\"] = \"\"\n",
    "    return {\"text\": create_prompt(row)}\n",
    "\n",
    "\n",
    "test_dataset = eval_dataset.map(create_prompt_no_anwer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gPQmq3gsai0I",
   "metadata": {
    "id": "gPQmq3gsai0I"
   },
   "source": [
    "We will add a custom W&B callback to the trainer so that we can sample and log model generations in W&B dashboard. Review [W&B HuggingFace documentation](https://docs.wandb.ai/guides/integrations/huggingface) for the most up-to-date best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d6748da-bbc7-4962-bbc4-1650ff18aefe",
   "metadata": {
    "id": "9d6748da-bbc7-4962-bbc4-1650ff18aefe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977480782,
     "user_tz": 240,
     "elapsed": 232,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    },
    "outputId": "7b0a4ca0-7080-445c-b2b1-2764eeda8e32"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    }
   ],
   "source": [
    "wandb_callback = LLMSampleCB(trainer, test_dataset, num_samples=10, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df6d1457-3c7a-47e6-994b-334dbe9c3d5e",
   "metadata": {
    "id": "df6d1457-3c7a-47e6-994b-334dbe9c3d5e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977480786,
     "user_tz": 240,
     "elapsed": 2,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": [
    "trainer.add_callback(wandb_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tA5MJVEDauaG",
   "metadata": {
    "id": "tA5MJVEDauaG"
   },
   "source": [
    "It's time to train!"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N83aujA8_GS1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746977740069,
     "user_tz": 240,
     "elapsed": 2636,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    },
    "outputId": "61b80917-90f9-4a48-d25e-a6c3de709a54"
   },
   "id": "N83aujA8_GS1",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5754789-2e15-4bc9-800c-01f8ffc625e8",
   "metadata": {
    "id": "d5754789-2e15-4bc9-800c-01f8ffc625e8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446,
     "referenced_widgets": [
      "cdc3fa33ada6492ea183f5b1f6421895",
      "5b20b90da3d44c2fab0b3730caa75e30",
      "062a81ec0ddc4e2eb0857f9d5eacb670",
      "68beb8cb3ab246039dc8a7a4c94e8578",
      "c0244f5c05e6446b9e97f73742a4be21",
      "aff97c0aa266424d92e78419bf999c49",
      "34fe25fdf81f46ff8e0faeb70a734560",
      "16ba7da7d47e4e17baba7d597cdc45ea",
      "46ac820e6c6b4f30ad4f1f5889763cf5",
      "a34c3b9272224b09b1ca1302262eadce",
      "222b2f4074cf42ceac69869b124828df"
     ]
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1746977977548,
     "user_tz": 240,
     "elapsed": 231866,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    },
    "outputId": "190d363e-f21d-4f22-8b64-3207eb248d89"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 03:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.359800</td>\n",
       "      <td>1.411796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdc3fa33ada6492ea183f5b1f6421895"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output/checkpoint-16)... Done. 1.0s\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'is_enabled'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b61caeea81b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2723\u001b[0m                     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m         \u001b[0;31m# Wait for the checkpoint to be uploaded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, args, state, control, model, processing_class, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_enabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'is_enabled'"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb6dbe-5128-405c-aecc-5b2564930f55",
   "metadata": {
    "id": "69eb6dbe-5128-405c-aecc-5b2564930f55"
   },
   "source": [
    "Check out the sample generations in your W&B workspace. We've trained on a very small sample of dataset, so likely they won't be good. Try to improve this result! Train on a larger dataset, experiment with different hyperparameters and settings. Then share a W&B report with your results. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a414b0-5a05-40f4-98ac-25c9717a7b84",
   "metadata": {
    "id": "95a414b0-5a05-40f4-98ac-25c9717a7b84",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1746977481587,
     "user_tz": 240,
     "elapsed": 112,
     "user": {
      "displayName": "Chad Coburn",
      "userId": "16006223513488087113"
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "cdc3fa33ada6492ea183f5b1f6421895": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b20b90da3d44c2fab0b3730caa75e30",
       "IPY_MODEL_062a81ec0ddc4e2eb0857f9d5eacb670",
       "IPY_MODEL_68beb8cb3ab246039dc8a7a4c94e8578"
      ],
      "layout": "IPY_MODEL_c0244f5c05e6446b9e97f73742a4be21"
     }
    },
    "5b20b90da3d44c2fab0b3730caa75e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aff97c0aa266424d92e78419bf999c49",
      "placeholder": "​",
      "style": "IPY_MODEL_34fe25fdf81f46ff8e0faeb70a734560",
      "value": "100%"
     }
    },
    "062a81ec0ddc4e2eb0857f9d5eacb670": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16ba7da7d47e4e17baba7d597cdc45ea",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46ac820e6c6b4f30ad4f1f5889763cf5",
      "value": 10
     }
    },
    "68beb8cb3ab246039dc8a7a4c94e8578": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a34c3b9272224b09b1ca1302262eadce",
      "placeholder": "​",
      "style": "IPY_MODEL_222b2f4074cf42ceac69869b124828df",
      "value": " 10/10 [01:51&lt;00:00, 11.18s/it]"
     }
    },
    "c0244f5c05e6446b9e97f73742a4be21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "aff97c0aa266424d92e78419bf999c49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34fe25fdf81f46ff8e0faeb70a734560": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16ba7da7d47e4e17baba7d597cdc45ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46ac820e6c6b4f30ad4f1f5889763cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a34c3b9272224b09b1ca1302262eadce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "222b2f4074cf42ceac69869b124828df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}